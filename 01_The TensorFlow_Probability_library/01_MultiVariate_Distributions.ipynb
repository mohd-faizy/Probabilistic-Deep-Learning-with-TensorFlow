{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be819eaf",
   "metadata": {},
   "source": [
    "# **Multivariate Distributions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fae77fd",
   "metadata": {},
   "source": [
    "## üìë Table of Contents\n",
    "\n",
    "- **1. [Foundation - What Are Multivariate Distributions?](#1-foundation---what-are-multivariate-distributions)**\n",
    "    - 1.1 [The Big Picture](#11-the-big-picture)\n",
    "\n",
    "- **2. [Setup & First Steps](#2-setup--first-steps)**\n",
    "    - 2.1 [Essential Imports & Setup](#21-essential-imports--setup)  \n",
    "    - 2.2 [Your First Multivariate Distribution - The Multivariate Normal](#22-your-first-multivariate-distribution---the-multivariate-normal)\n",
    "\n",
    "- **3. [Multivariate vs Univariate Batching](#3-multivariate-vs-univariate-batching)**\n",
    "    - 3.1 [The Critical Distinction: Multivariate vs Batched Univariate](#31-the-critical-distinction-multivariate-vs-batched-univariate)\n",
    "\n",
    "- **4. [Log Probability Computations](#4-log-probability-computations)**\n",
    "    - 4.1 [Understanding Joint vs Independent Probabilities](#41-understanding-joint-vs-independent-probabilities)\n",
    "\n",
    "- **5. [Batch Multivariate Distributions](#5-batch-multivariate-distributions)**\n",
    "    - 5.1 [Multiple Multivariate Distributions](#51-multiple-multivariate-distributions)  \n",
    "    - 5.2 [Sampling from Batched Multivariate](#52-sampling-from-batched-multivariate)\n",
    "\n",
    "- **6. [Advanced Shape Analysis](#6-advanced-shape-analysis)**\n",
    "    - 6.1 [Complex Batch-Event Shape Interactions](#61-complex-batch-event-shape-interactions)  \n",
    "    - 6.2 [Shape Rules Summary](#62-shape-rules-summary)\n",
    "\n",
    "- **7. [Types of Multivariate Distributions](#7-types-of-multivariate-distributions)**\n",
    "    - 7.1 [MultivariateNormal Family](#71-multivariatenormal-family)  \n",
    "    - 7.2 [Other Multivariate Distributions](#72-other-multivariate-distributions)\n",
    "\n",
    "- **8. [Professional Patterns & Best Practices](#8-professional-patterns--best-practices)**\n",
    "    - 8.1 [Efficient Covariance Parameterization](#81-efficient-covariance-parameterization)  \n",
    "    - 8.2 [Covariance Matrix Validation](#82-covariance-matrix-validation)  \n",
    "    - 8.3 [Loss Functions for Multivariate Outputs](#83-loss-functions-for-multivariate-outputs)\n",
    "\n",
    "- **9. [Expert Applications](#9-expert-applications)**\n",
    "    - 9.1 [Uncertainty Quantification for Multivariate Outputs](#91-uncertainty-quantification-for-multivariate-outputs)  \n",
    "    - 9.2 [Custom Multivariate Distribution](#92-custom-multivariate-distribution)  \n",
    "    - 9.3 [Correlation Analysis](#93-correlation-analysis)\n",
    "\n",
    "- **10. [Complete Reference Guide](#10-complete-reference-guide)**\n",
    "    - 10.1 [Multivariate Distribution Constructor Cheat Sheet](#101-multivariate-distribution-constructor-cheat-sheet)  \n",
    "    - 10.2 [Essential Multivariate Operations Reference](#102-essential-multivariate-operations-reference)\n",
    "\n",
    "- **[Final Notes](#final-notes)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b6182a",
   "metadata": {},
   "source": [
    "## 1. **Foundation - What Are Multivariate Distributions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbc3c4a",
   "metadata": {},
   "source": [
    "### 1.1 **The Big Picture**\n",
    "Multivariate distributions are **multi-dimensional random variables** that model relationships between multiple correlated features simultaneously. Unlike univariate distributions that output scalars, multivariate distributions produce **vectors** where each component can be dependent on others.[1][2]\n",
    "\n",
    "**Key Insight**: Multivariate distributions capture **joint probability relationships** between multiple variables, enabling modeling of correlation, covariance, and complex dependencies that univariate distributions cannot represent.\n",
    "\n",
    "**Critical Difference**: \n",
    "- **Univariate**: `event_shape = []` (scalar outcomes)\n",
    "- **Multivariate**: `event_shape = [k]` (k-dimensional vector outcomes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb53da9",
   "metadata": {},
   "source": [
    "## 2. **Setup & First Steps**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e339565",
   "metadata": {},
   "source": [
    "### 2.1 **Essential Imports & Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23398c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing TensorFlow Probability library\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "\n",
    "# Standard alias for distributions\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6115a96b",
   "metadata": {},
   "source": [
    "### 2.2 **Your First Multivariate Distribution - The Multivariate Normal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9207e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[], event_shape=[2], dtype=float32)\n",
      "Batch shape: ()\n",
      "Event shape: (2,)\n",
      "Data type: <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Defining our first multivariate distribution object\n",
    "\"\"\"\n",
    "2D Multivariate Normal distribution with diagonal covariance\n",
    "Mean: [-1.0, 0.5], Standard deviations: [1.0, 1.5]\n",
    "\"\"\"\n",
    "mv_normal = tfd.MultivariateNormalDiag(loc=[-1., 0.5], scale_diag=[1., 1.5])\n",
    "print(mv_normal)\n",
    "# Output: <tfp.distributions.MultivariateNormalDiag 'MultivariateNormalDiag' batch_shape=[] event_shape=[2] dtype=float32>\n",
    "\n",
    "# Inspect the distribution properties\n",
    "print(\"Batch shape:\", mv_normal.batch_shape)  # []\n",
    "print(\"Event shape:\", mv_normal.event_shape)  # [2]\n",
    "print(\"Data type:\", mv_normal.dtype)          # float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f562189",
   "metadata": {},
   "source": [
    "**Key Properties Explained:**\n",
    "- **`batch_shape=[]`**: Single distribution (no batching)\n",
    "- **`event_shape=`**: 2-dimensional vectors (bivariate)[2]\n",
    "- **`dtype=float32`**: Numerical precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdb8c78",
   "metadata": {},
   "source": [
    "## 3. **Multivariate vs Univariate Batching**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f7c116",
   "metadata": {},
   "source": [
    "### 3.1 **The Critical Distinction: Multivariate vs Batched Univariate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5944185e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate Normal: tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[], event_shape=[2], dtype=float32)\n",
      "Multivariate samples shape: (3, 2)\n",
      "Multivariate samples:\n",
      " tf.Tensor(\n",
      "[[-0.6725315  -0.76393867]\n",
      " [-0.6805663  -1.6113279 ]\n",
      " [-3.3880599  -1.0588717 ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# MULTIVARIATE DISTRIBUTION - Single 2D distribution\n",
    "mv_normal = tfd.MultivariateNormalDiag(loc=[-1., 0.5], scale_diag=[1., 1.5])\n",
    "print(\"Multivariate Normal:\", mv_normal)\n",
    "# Output: batch_shape=[], event_shape=[2]\n",
    "\n",
    "# Sample from multivariate (returns 2D vectors)\n",
    "mv_samples = mv_normal.sample(3)\n",
    "print(\"Multivariate samples shape:\", mv_samples.shape)  # (3, 2)\n",
    "print(\"Multivariate samples:\\n\", mv_samples)\n",
    "\n",
    "# Output: Each row is a 2D sample from the joint distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7958176c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batched Normal: tfp.distributions.Normal(\"Normal\", batch_shape=[2], event_shape=[], dtype=float32)\n",
      "Batched samples shape: (3, 2)\n",
      "Batched samples:\n",
      " tf.Tensor(\n",
      "[[-0.9157754  -0.7913556 ]\n",
      " [-0.62187696  0.4922056 ]\n",
      " [-1.494532    1.4267287 ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# BATCHED UNIVARIATE DISTRIBUTION - Two independent 1D distributions  \n",
    "batched_normal = tfd.Normal(loc=[-1., 0.5], scale=[1., 1.5])\n",
    "print(\"Batched Normal:\", batched_normal)\n",
    "# Output: batch_shape=[2], event_shape=[]\n",
    "\n",
    "# Sample from batched univariate (returns independent scalars)\n",
    "batch_samples = batched_normal.sample(3)\n",
    "print(\"Batched samples shape:\", batch_samples.shape)  # (3, 2)\n",
    "print(\"Batched samples:\\n\", batch_samples)\n",
    "\n",
    "\n",
    "# Output: Each column is independent samples from separate distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52329c21",
   "metadata": {},
   "source": [
    "**üéØ Key Difference:**\n",
    "- **Multivariate**: Models **joint relationships** between variables\n",
    "- **Batched Univariate**: Models **independent** variables processed together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33443b2",
   "metadata": {},
   "source": [
    "## 4. **Log Probability Computations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd82e6",
   "metadata": {},
   "source": [
    "### 4.1 **Understanding Joint vs Independent Probabilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad39dda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate log prob: tf.Tensor(-4.1388974, shape=(), dtype=float32)\n",
      "Shape: ()\n",
      "Batched log prob: tf.Tensor([-1.6389385 -2.499959 ], shape=(2,), dtype=float32)\n",
      "Shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "# MULTIVARIATE LOG PROBABILITY - Joint probability\n",
    "mv_normal = tfd.MultivariateNormalDiag(loc=[-1., 0.5], scale_diag=[1., 1.5])\n",
    "mv_log_prob = mv_normal.log_prob([0.2, -1.8])\n",
    "print(\"Multivariate log prob:\", mv_log_prob)\n",
    "print(\"Shape:\", mv_log_prob.shape)  # ()\n",
    "# Output: Single scalar - joint log probability of the vector [0.2, -1.8]\n",
    "\n",
    "# BATCHED UNIVARIATE LOG PROBABILITY - Independent probabilities  \n",
    "batched_normal = tfd.Normal(loc=[-1., 0.5], scale=[1., 1.5])\n",
    "batch_log_prob = batched_normal.log_prob([0.2, -1.8])\n",
    "print(\"Batched log prob:\", batch_log_prob)\n",
    "print(\"Shape:\", batch_log_prob.shape)  # (2,)\n",
    "# Output: [log P(0.2), log P(-1.8)] - separate log probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6661528a",
   "metadata": {},
   "source": [
    "**Mathematical Insight:**\n",
    "- **Multivariate**: `log P(x‚ÇÅ, x‚ÇÇ)` - joint probability\n",
    "- **Batched**: `[log P(x‚ÇÅ), log P(x‚ÇÇ)]` - independent probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed4cb24",
   "metadata": {},
   "source": [
    "## 5. **Batch Multivariate Distributions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e094946",
   "metadata": {},
   "source": [
    "### 5.1 **Multiple Multivariate Distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e754eeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[3], event_shape=[2], dtype=float32)\n",
      "Batch shape: (3,)\n",
      "Event shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "# Create batch of 3 different 2D multivariate normal distributions\n",
    "batched_mv_normal = tfd.MultivariateNormalDiag(\n",
    "    loc=[[-1., 0.5], [2., 0], [-0.5, 1.5]],        # 3 different mean vectors\n",
    "    scale_diag=[[1., 1.5], [2., 0.5], [1., 1.]]     # 3 different scale vectors\n",
    ")\n",
    "\n",
    "print(batched_mv_normal)\n",
    "# Output: <tfp.distributions.MultivariateNormalDiag 'MultivariateNormalDiag' batch_shape=[3] event_shape=[2] dtype=float32>\n",
    "\n",
    "print(\"Batch shape:\", batched_mv_normal.batch_shape)  # [3] - 3 distributions\n",
    "print(\"Event shape:\", batched_mv_normal.event_shape)  # [2] - 2D vectors each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2c6158",
   "metadata": {},
   "source": [
    "### 5.2 **Sampling from Batched Multivariate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62b44ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batched multivariate samples shape: (2, 3, 2)\n",
      "Batched multivariate samples:\n",
      " tf.Tensor(\n",
      "[[[-1.5590973  -1.8588896 ]\n",
      "  [ 0.93055725  0.4027528 ]\n",
      "  [ 1.8730333   0.66612303]]\n",
      "\n",
      " [[-0.69388777 -1.8304234 ]\n",
      "  [ 6.532099    0.18987766]\n",
      "  [-0.2143586   2.2664626 ]]], shape=(2, 3, 2), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nShape interpretation: (sample_shape, batch_shape, event_shape)\\n- 2 samples\\n- 3 different distributions  \\n- 2D vectors each\\n\\nOutput structure:\\n[[[sample1_dist1_x1, sample1_dist1_x2],   # Sample 1 from distribution 1\\n  [sample1_dist2_x1, sample1_dist2_x2],   # Sample 1 from distribution 2  \\n  [sample1_dist3_x1, sample1_dist3_x2]],  # Sample 1 from distribution 3\\n\\n [[sample2_dist1_x1, sample2_dist1_x2],   # Sample 2 from distribution 1\\n  [sample2_dist2_x1, sample2_dist2_x2],   # Sample 2 from distribution 2\\n  [sample2_dist3_x1, sample2_dist3_x2]]]  # Sample 2 from distribution 3\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample from batch of multivariate distributions\n",
    "batched_mv_normal = tfd.MultivariateNormalDiag(\n",
    "    loc=[[-1., 0.5], [2., 0], [-0.5, 1.5]],\n",
    "    scale_diag=[[1., 1.5], [2., 0.5], [1., 1.]]\n",
    ")\n",
    "\n",
    "batch_mv_samples = batched_mv_normal.sample(2)\n",
    "print(\"Batched multivariate samples shape:\", batch_mv_samples.shape)  # (2, 3, 2)\n",
    "print(\"Batched multivariate samples:\\n\", batch_mv_samples)\n",
    "\n",
    "\"\"\"\n",
    "Shape interpretation: (sample_shape, batch_shape, event_shape)\n",
    "- 2 samples\n",
    "- 3 different distributions  \n",
    "- 2D vectors each\n",
    "\n",
    "Output structure:\n",
    "[[[sample1_dist1_x1, sample1_dist1_x2],   # Sample 1 from distribution 1\n",
    "  [sample1_dist2_x1, sample1_dist2_x2],   # Sample 1 from distribution 2  \n",
    "  [sample1_dist3_x1, sample1_dist3_x2]],  # Sample 1 from distribution 3\n",
    " \n",
    " [[sample2_dist1_x1, sample2_dist1_x2],   # Sample 2 from distribution 1\n",
    "  [sample2_dist2_x1, sample2_dist2_x2],   # Sample 2 from distribution 2\n",
    "  [sample2_dist3_x1, sample2_dist3_x2]]]  # Sample 2 from distribution 3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10247289",
   "metadata": {},
   "source": [
    "## 6. **Advanced Shape Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdb3588",
   "metadata": {},
   "source": [
    "### 6.1 **Complex Batch-Event Shape Interactions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90999b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex batch-multivariate: tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[2], event_shape=[3], dtype=float32)\n",
      "Batch shape: (2,)\n",
      "Event shape: (3,)\n",
      "Result shape: (2,)\n",
      "Result values: tf.Tensor([ -3.9172401 -11.917513 ], shape=(2,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSHAPE ANALYSIS:\\n- Input: [0., -1., 1.] has shape (3,) - matches event_shape=[3] ‚úì\\n- batch_shape=[2] means we have 2 different distributions\\n- Each distribution computes log_prob for the same input vector\\n- Output shape: (2,) - one log probability per distribution\\n\\nRESULT INTERPRETATION:\\n[log_prob_dist1, log_prob_dist2] where:\\n- log_prob_dist1: log P([0., -1., 1.]) under distribution 1\\n- log_prob_dist2: log P([0., -1., 1.]) under distribution 2\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create complex batched multivariate distribution\n",
    "batched_mv_normal = tfd.MultivariateNormalDiag(\n",
    "    loc=[[0.3, 0.8, 1.1], [2.3, -0.3, -1.]],           # 2 distributions\n",
    "    scale_diag=[[1.5, 1., 0.4], [2.5, 1.5, 0.5]]       # 3D vectors each\n",
    ")\n",
    "\n",
    "print(\"Complex batch-multivariate:\", batched_mv_normal)\n",
    "print(\"Batch shape:\", batched_mv_normal.batch_shape)  # [2]\n",
    "print(\"Event shape:\", batched_mv_normal.event_shape)  # [3]\n",
    "\n",
    "# **Question: What is the shape of the Tensor returned by the following?**\n",
    "result = batched_mv_normal.log_prob([0., -1., 1.])\n",
    "print(\"Result shape:\", result.shape)  # (2,)\n",
    "print(\"Result values:\", result)\n",
    "\n",
    "\"\"\"\n",
    "SHAPE ANALYSIS:\n",
    "- Input: [0., -1., 1.] has shape (3,) - matches event_shape=[3] ‚úì\n",
    "- batch_shape=[2] means we have 2 different distributions\n",
    "- Each distribution computes log_prob for the same input vector\n",
    "- Output shape: (2,) - one log probability per distribution\n",
    "\n",
    "RESULT INTERPRETATION:\n",
    "[log_prob_dist1, log_prob_dist2] where:\n",
    "- log_prob_dist1: log P([0., -1., 1.]) under distribution 1\n",
    "- log_prob_dist2: log P([0., -1., 1.]) under distribution 2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59b5890",
   "metadata": {},
   "source": [
    "### 6.2 **Shape Rules Summary**\n",
    "\n",
    "| **Distribution Type** | **Batch Shape** | **Event Shape** | **Sample Shape** | **Final Output** |\n",
    "|----------------------|----------------|-----------------|------------------|------------------|\n",
    "| **Univariate** | `[]` | `[]` | `[n]` | `(n,)` |\n",
    "| **Batched Univariate** | `[k]` | `[]` | `[n]` | `(n, k)` |\n",
    "| **Multivariate** | `[]` | `[d]` | `[n]` | `(n, d)` |\n",
    "| **Batched Multivariate** | `[k]` | `[d]` | `[n]` | `(n, k, d)` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e472b89",
   "metadata": {},
   "source": [
    "## 7. **Types of Multivariate Distributions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f5f66f",
   "metadata": {},
   "source": [
    "### 7.1 **MultivariateNormal Family**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1398321d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagonal covariance shape: (2, 2)\n"
     ]
    }
   ],
   "source": [
    "# === DIAGONAL COVARIANCE (Independent components) ===\n",
    "mv_diag = tfd.MultivariateNormalDiag(\n",
    "    loc=[0., 1.],\n",
    "    scale_diag=[2., 0.5]  # Independent variances\n",
    ")\n",
    "print(\"Diagonal covariance shape:\", mv_diag.covariance().shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "52729410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full covariance:\n",
      " tf.Tensor(\n",
      "[[nan nan]\n",
      " [nan nan]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# === FULL COVARIANCE (Correlated components) ===\n",
    "covariance_matrix = [[4., 1.2],   # œÉ‚ÇÅ¬≤=4, œÉ‚ÇÅœÉ‚ÇÇœÅ=1.2  \n",
    "                     [1.2, 0.25]] # œÉ‚ÇÇ¬≤=0.25\n",
    "mv_full = tfd.MultivariateNormalFullCovariance(\n",
    "    loc=[0., 1.],\n",
    "    covariance_matrix=covariance_matrix\n",
    ")\n",
    "print(\"Full covariance:\\n\", mv_full.covariance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "88d520af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriL covariance:\n",
      " tf.Tensor(\n",
      "[[4.   1.2 ]\n",
      " [1.2  0.61]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# === TRIANGULAR FORM (Efficient parameterization) ===\n",
    "scale_tril = [[2., 0.],     # Lower triangular Cholesky factor\n",
    "              [0.6, 0.5]]   # Œ£ = L L^T\n",
    "mv_tril = tfd.MultivariateNormalTriL(\n",
    "    loc=[0., 1.],\n",
    "    scale_tril=scale_tril\n",
    ")\n",
    "print(\"TriL covariance:\\n\", mv_tril.covariance())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f935e95",
   "metadata": {},
   "source": [
    "### 7.2 **Other Multivariate Distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26269198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dirichlet samples (sum to 1):\n",
      " tf.Tensor(\n",
      "[[0.11105072 0.36103418 0.5279151 ]\n",
      " [0.1413823  0.20639223 0.65222555]\n",
      " [0.04453953 0.54176676 0.41369376]], shape=(3, 3), dtype=float32)\n",
      "Row sums: tf.Tensor([1.        1.0000001 1.       ], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# === DIRICHLET DISTRIBUTION (Probability Simplex) ===\n",
    "# Perfect for categorical probabilities that sum to 1\n",
    "dirichlet = tfd.Dirichlet(concentration=[1., 2., 3.])\n",
    "dirichlet_sample = dirichlet.sample(3)\n",
    "print(\"Dirichlet samples (sum to 1):\\n\", dirichlet_sample)\n",
    "print(\"Row sums:\", tf.reduce_sum(dirichlet_sample, axis=1))  # All ‚âà 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c360f88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student-T samples:\n",
      " tf.Tensor(\n",
      "[[ 0.59606385 -1.8027201 ]\n",
      " [-3.6440275  -1.564675  ]\n",
      " [-0.29609033 -0.02172232]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# === MULTIVARIATE STUDENT-T (Heavy-tailed alternative) ===\n",
    "mv_student_t = tfd.MultivariateStudentTLinearOperator(\n",
    "    df=3.,  # Degrees of freedom\n",
    "    loc=[0., 0.],\n",
    "    scale=tf.linalg.LinearOperatorIdentity(2)\n",
    ")\n",
    "print(\"Student-T samples:\\n\", mv_student_t.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6d85908f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit vector samples:\n",
      " tf.Tensor(\n",
      "[[-0.08670211 -0.27101254  0.95866317]\n",
      " [ 0.77641785  0.31677374  0.5448207 ]\n",
      " [ 0.58069456 -0.32908437  0.7446458 ]], shape=(3, 3), dtype=float32)\n",
      "Norms (should be 1): tf.Tensor([1.         0.99999994 1.        ], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# === VON MISES-FISHER (Directional data on sphere) ===\n",
    "# For modeling directions, angles, or unit vectors\n",
    "von_mises_fisher = tfd.VonMisesFisher(\n",
    "    mean_direction=[1., 0., 0.],  # 3D unit vector\n",
    "    concentration=2.0\n",
    ")\n",
    "vmf_samples = von_mises_fisher.sample(3)\n",
    "print(\"Unit vector samples:\\n\", vmf_samples)\n",
    "print(\"Norms (should be 1):\", tf.norm(vmf_samples, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e757414",
   "metadata": {},
   "source": [
    "## 8. **Professional Patterns & Best Practices**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985e8f2c",
   "metadata": {},
   "source": [
    "### 8.1 **Efficient Covariance Parameterization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc7c3a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stable_multivariate_normal(raw_loc, raw_scale_diag, raw_scale_tril=None):\n",
    "    \"\"\"\n",
    "    Create numerically stable multivariate normal from raw parameters\n",
    "    \"\"\"\n",
    "    loc = raw_loc  # Location parameter needs no transformation\n",
    "    \n",
    "    if raw_scale_tril is None:\n",
    "        # Diagonal covariance case\n",
    "        scale_diag = tf.nn.softplus(raw_scale_diag) + 1e-6\n",
    "        return tfd.MultivariateNormalDiag(loc=loc, scale_diag=scale_diag)\n",
    "    else:\n",
    "        # Full covariance case using triangular parameterization\n",
    "        # Ensure positive diagonal elements\n",
    "        diag_part = tf.nn.softplus(tf.linalg.diag_part(raw_scale_tril)) + 1e-6\n",
    "        scale_tril = tf.linalg.set_diag(raw_scale_tril, diag_part)\n",
    "        return tfd.MultivariateNormalTriL(loc=loc, scale_tril=scale_tril)\n",
    "\n",
    "# Example usage in neural network\n",
    "class MultivariateOutput(tf.keras.layers.Layer):\n",
    "    def __init__(self, event_size, use_full_covariance=False):\n",
    "        super().__init__()\n",
    "        self.event_size = event_size\n",
    "        self.use_full_covariance = use_full_covariance\n",
    "        \n",
    "        # Location parameters\n",
    "        self.loc_layer = tf.keras.layers.Dense(event_size)\n",
    "        \n",
    "        if use_full_covariance:\n",
    "            # Full covariance matrix (triangular parameterization)\n",
    "            tril_size = event_size * (event_size + 1) // 2\n",
    "            self.scale_layer = tf.keras.layers.Dense(tril_size)\n",
    "        else:\n",
    "            # Diagonal covariance\n",
    "            self.scale_layer = tf.keras.layers.Dense(event_size)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        raw_loc = self.loc_layer(inputs)\n",
    "        raw_scale = self.scale_layer(inputs)\n",
    "        \n",
    "        if self.use_full_covariance:\n",
    "            # Construct lower triangular matrix\n",
    "            scale_tril = tfp.bijectors.FillScaleTriL()(raw_scale)\n",
    "            return tfd.MultivariateNormalTriL(loc=raw_loc, scale_tril=scale_tril)\n",
    "        else:\n",
    "            scale_diag = tf.nn.softplus(raw_scale) + 1e-6\n",
    "            return tfd.MultivariateNormalDiag(loc=raw_loc, scale_diag=scale_diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fa941b",
   "metadata": {},
   "source": [
    "### 8.2 **Covariance Matrix Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "18548690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symmetric: True, Positive Definite: False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def validate_covariance_matrix(cov_matrix):\n",
    "    \"\"\"\n",
    "    Validate that a matrix is a valid covariance matrix\n",
    "    \"\"\"\n",
    "    # Convert input to TensorFlow tensor\n",
    "    cov_matrix = tf.convert_to_tensor(cov_matrix, dtype=tf.float32)\n",
    "    \n",
    "    # Check symmetry\n",
    "    is_symmetric = tf.reduce_all(\n",
    "        tf.abs(cov_matrix - tf.transpose(cov_matrix)) < 1e-6\n",
    "    )\n",
    "    \n",
    "    # Check positive definiteness via eigenvalues\n",
    "    eigenvals = tf.linalg.eigvals(cov_matrix)\n",
    "    # Eigenvalues might be complex, so take the real part\n",
    "    is_positive_definite = tf.reduce_all(tf.math.real(eigenvals) > 1e-6)\n",
    "    \n",
    "    return is_symmetric, is_positive_definite\n",
    "\n",
    "\n",
    "# Example validation\n",
    "cov_matrix = [[4.0, 1.2], [1.2, 0.25]]\n",
    "is_sym, is_pd = validate_covariance_matrix(cov_matrix)\n",
    "print(f\"Symmetric: {is_sym.numpy()}, Positive Definite: {is_pd.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "97a8488e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symmetric: True, Positive Definite: True\n"
     ]
    }
   ],
   "source": [
    "def validate_covariance_matrix_cholesky(cov_matrix):\n",
    "    \"\"\"\n",
    "    Validate covariance matrix using Cholesky decomposition\n",
    "    \"\"\"\n",
    "    cov_matrix = tf.convert_to_tensor(cov_matrix, dtype=tf.float32)\n",
    "    \n",
    "    # Check symmetry\n",
    "    is_symmetric = tf.reduce_all(\n",
    "        tf.abs(cov_matrix - tf.transpose(cov_matrix)) < 1e-6\n",
    "    )\n",
    "    \n",
    "    # Check positive definiteness using Cholesky decomposition\n",
    "    try:\n",
    "        tf.linalg.cholesky(cov_matrix)\n",
    "        is_positive_definite = tf.constant(True)\n",
    "    except tf.errors.InvalidArgumentError:\n",
    "        is_positive_definite = tf.constant(False)\n",
    "    \n",
    "    return is_symmetric, is_positive_definite\n",
    "\n",
    "\n",
    "# Example\n",
    "cov_matrix = [[4.0, 1.2], [1.2, 0.25]]\n",
    "is_sym, is_pd = validate_covariance_matrix_cholesky(cov_matrix)\n",
    "print(f\"Symmetric: {is_sym.numpy()}, Positive Definite: {is_pd.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4666935",
   "metadata": {},
   "source": [
    "### 8.3 **Loss Functions for Multivariate Outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1bdfe802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_regression_loss(y_true, distribution):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood loss for multivariate regression\n",
    "    \"\"\"\n",
    "    return -tf.reduce_mean(distribution.log_prob(y_true))\n",
    "\n",
    "def multivariate_classification_loss(y_true_one_hot, dirichlet_dist):\n",
    "    \"\"\"\n",
    "    Loss for categorical outcomes using Dirichlet distribution\n",
    "    \"\"\"\n",
    "    return -tf.reduce_mean(dirichlet_dist.log_prob(y_true_one_hot))\n",
    "\n",
    "# Example training step for multivariate regression\n",
    "@tf.function\n",
    "def multivariate_train_step(features, targets, model, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Model outputs multivariate distribution\n",
    "        pred_distribution = model(features)\n",
    "        \n",
    "        # Compute negative log-likelihood\n",
    "        nll_loss = multivariate_regression_loss(targets, pred_distribution)\n",
    "        \n",
    "        # Add regularization\n",
    "        reg_loss = sum(model.losses)\n",
    "        total_loss = nll_loss + 0.01 * reg_loss\n",
    "    \n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return total_loss, nll_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d8cb4e",
   "metadata": {},
   "source": [
    "## 9. **Expert Applications**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea7775",
   "metadata": {},
   "source": [
    "### 9.1 **Uncertainty Quantification for Multivariate Outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "10a50d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_uncertainty_prediction(model, x_test, n_samples=100):\n",
    "    \"\"\"\n",
    "    Predict multivariate outputs with uncertainty quantification\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        dist = model(x_test, training=True)\n",
    "        pred_sample = dist.sample()\n",
    "        predictions.append(pred_sample)\n",
    "    \n",
    "    predictions = tf.stack(predictions)  # (n_samples, batch_size, event_size)\n",
    "    \n",
    "    # Compute statistics across samples\n",
    "    mean_pred = tf.reduce_mean(predictions, axis=0)\n",
    "    std_pred = tf.math.reduce_std(predictions, axis=0)\n",
    "    \n",
    "    # Compute covariance for each test point\n",
    "    centered_preds = predictions - tf.expand_dims(mean_pred, 0)\n",
    "    covariance_pred = tf.reduce_mean(\n",
    "        tf.matmul(centered_preds[..., :, None], centered_preds[..., None, :]), \n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'mean': mean_pred,\n",
    "        'std': std_pred,\n",
    "        'covariance': covariance_pred,\n",
    "        'samples': predictions\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64244c3",
   "metadata": {},
   "source": [
    "### 9.2 **Custom Multivariate Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "41d0b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruncatedMultivariateNormal:\n",
    "    \"\"\"\n",
    "    Custom truncated multivariate normal distribution\n",
    "    \"\"\"\n",
    "    def __init__(self, loc, covariance_matrix, low, high):\n",
    "        self.base_dist = tfd.MultivariateNormalFullCovariance(\n",
    "            loc=loc, covariance_matrix=covariance_matrix\n",
    "        )\n",
    "        self.low = tf.convert_to_tensor(low)\n",
    "        self.high = tf.convert_to_tensor(high)\n",
    "        \n",
    "    def sample(self, sample_shape=()):\n",
    "        \"\"\"Rejection sampling for truncated multivariate normal\"\"\"\n",
    "        # Simple clipping approach (not mathematically correct)\n",
    "        samples = self.base_dist.sample(sample_shape)\n",
    "        return tf.clip_by_value(samples, self.low, self.high)\n",
    "    \n",
    "    def log_prob(self, value):\n",
    "        \"\"\"Log probability with boundary conditions\"\"\"\n",
    "        base_log_prob = self.base_dist.log_prob(value)\n",
    "        \n",
    "        # Check if all components are within bounds\n",
    "        in_bounds = tf.logical_and(\n",
    "            tf.reduce_all(value >= self.low, axis=-1),\n",
    "            tf.reduce_all(value <= self.high, axis=-1)\n",
    "        )\n",
    "        \n",
    "        return tf.where(in_bounds, base_log_prob, -np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6103f79d",
   "metadata": {},
   "source": [
    "### 9.3 **Correlation Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cf2d1b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample correlation matrix:\n",
      " tf.Tensor(\n",
      "[[1.         0.79317343]\n",
      " [0.79317343 1.        ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def analyze_correlation_structure(samples):\n",
    "    \"\"\"\n",
    "    Analyze correlation structure of multivariate samples\n",
    "    \"\"\"\n",
    "    # Compute sample correlation matrix\n",
    "    centered_samples = samples - tf.reduce_mean(samples, axis=0)\n",
    "    # Fix: Cast the divisor to float32 to match the tensor dtype\n",
    "    divisor = tf.cast(tf.shape(samples)[0] - 1, tf.float32)\n",
    "    covariance = tf.matmul(centered_samples, centered_samples, transpose_a=True) / divisor\n",
    "    \n",
    "    # Convert to correlation matrix\n",
    "    std_devs = tf.sqrt(tf.linalg.diag_part(covariance))\n",
    "    correlation = covariance / tf.matmul(std_devs[:, None], std_devs[None, :])\n",
    "    \n",
    "    return {\n",
    "        'covariance': covariance,\n",
    "        'correlation': correlation,\n",
    "        'std_devs': std_devs\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage\n",
    "mv_dist = tfd.MultivariateNormalFullCovariance(\n",
    "    loc=[0., 0.], \n",
    "    covariance_matrix=[[1., 0.8], [0.8, 1.]]\n",
    ")\n",
    "samples = mv_dist.sample(1000)\n",
    "analysis = analyze_correlation_structure(samples)\n",
    "print(\"Sample correlation matrix:\\n\", analysis['correlation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b66456",
   "metadata": {},
   "source": [
    "Using TensorFlow's Built-in Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f02678aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample correlation matrix:\n",
      "[[1.        0.8004023]\n",
      " [0.8004023 1.0000001]]\n",
      "\n",
      "Covariance matrix:\n",
      "[[1.0191175 0.828036 ]\n",
      " [0.828036  1.0501652]]\n",
      "\n",
      "Number of samples: 1000\n"
     ]
    }
   ],
   "source": [
    "def analyze_correlation_structure_robust(samples):\n",
    "    \"\"\"\n",
    "    Robust correlation analysis with comprehensive error handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        samples = tf.convert_to_tensor(samples, dtype=tf.float32)\n",
    "        \n",
    "        # Validate input shape\n",
    "        if len(samples.shape) != 2:\n",
    "            raise ValueError(\"Samples must be a 2D tensor (n_samples, n_features)\")\n",
    "        \n",
    "        n_samples, n_features = tf.shape(samples)[0], tf.shape(samples)[1]\n",
    "        \n",
    "        if n_samples < 2:\n",
    "            raise ValueError(\"Need at least 2 samples for correlation analysis\")\n",
    "        \n",
    "        # Compute statistics\n",
    "        n_samples_float = tf.cast(n_samples, tf.float32)\n",
    "        mean_vals = tf.reduce_mean(samples, axis=0)\n",
    "        centered_samples = samples - mean_vals\n",
    "        \n",
    "        # Covariance matrix\n",
    "        covariance = tf.matmul(centered_samples, centered_samples, transpose_a=True) / (n_samples_float - 1)\n",
    "        \n",
    "        # Standard deviations\n",
    "        variances = tf.linalg.diag_part(covariance)\n",
    "        std_devs = tf.sqrt(tf.maximum(variances, 1e-8))  # Avoid sqrt of negative numbers\n",
    "        \n",
    "        # Correlation matrix\n",
    "        outer_std = tf.matmul(std_devs[:, None], std_devs[None, :])\n",
    "        correlation = covariance / tf.maximum(outer_std, 1e-8)  # Avoid division by zero\n",
    "        \n",
    "        return {\n",
    "            'covariance': covariance,\n",
    "            'correlation': correlation,\n",
    "            'std_devs': std_devs,\n",
    "            'mean': mean_vals,\n",
    "            'n_samples': n_samples,\n",
    "            'n_features': n_features\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in correlation analysis: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage\n",
    "mv_dist = tfd.MultivariateNormalFullCovariance(\n",
    "    loc=[0., 0.], \n",
    "    covariance_matrix=[[1., 0.8], [0.8, 1.]]\n",
    ")\n",
    "samples = mv_dist.sample(1000)\n",
    "analysis = analyze_correlation_structure_robust(samples)\n",
    "\n",
    "if analysis:\n",
    "    print(\"Sample correlation matrix:\")\n",
    "    print(analysis['correlation'].numpy())\n",
    "    print(\"\\nCovariance matrix:\")\n",
    "    print(analysis['covariance'].numpy())\n",
    "    print(f\"\\nNumber of samples: {analysis['n_samples'].numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e74b53c",
   "metadata": {},
   "source": [
    "## 10. **Complete Reference Guide**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1cb689",
   "metadata": {},
   "source": [
    "### 10.1 **Multivariate Distribution Constructor Cheat Sheet**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fee06eb",
   "metadata": {},
   "source": [
    "```python\n",
    "# === MULTIVARIATE NORMAL FAMILY ===\n",
    "# Diagonal covariance (independent components)\n",
    "tfd.MultivariateNormalDiag(loc=[0., 1.], scale_diag=[1., 2.])\n",
    "\n",
    "# Full covariance (correlated components) \n",
    "tfd.MultivariateNormalFullCovariance(loc=[0., 1.], covariance_matrix=[[1., 0.5], [0.5, 2.]])\n",
    "\n",
    "# Triangular parameterization (efficient)\n",
    "tfd.MultivariateNormalTriL(loc=[0., 1.], scale_tril=[[1., 0.], [0.5, 1.4]])\n",
    "\n",
    "# Linear operator (advanced)\n",
    "tfd.MultivariateNormalLinearOperator(loc=[0., 1.], scale=tfp.bijectors.ScaleLinearOperator(...))\n",
    "\n",
    "# === OTHER MULTIVARIATE DISTRIBUTIONS ===\n",
    "# Probability simplex\n",
    "tfd.Dirichlet(concentration=[1., 2., 3.])\n",
    "\n",
    "# Heavy-tailed multivariate\n",
    "tfd.MultivariateStudentTLinearOperator(df=3., loc=[0., 0.], scale=...)\n",
    "\n",
    "# Directional data (unit sphere)\n",
    "tfd.VonMisesFisher(mean_direction=[1., 0., 0.], concentration=2.)\n",
    "\n",
    "# Matrix-valued distributions  \n",
    "tfd.MatrixNormalLinearOperator(loc=matrix_loc, scale_row=..., scale_column=...)\n",
    "\n",
    "# Correlation matrices\n",
    "tfd.LKJ(dimension=3, concentration=2.)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5187ec",
   "metadata": {},
   "source": [
    "### 10.2 **Essential Multivariate Operations Reference**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d781f2de",
   "metadata": {},
   "source": [
    "```python\n",
    "# Creating multivariate distribution\n",
    "mv_dist = tfd.MultivariateNormalDiag(loc=[0., 1.], scale_diag=[1., 2.])\n",
    "\n",
    "# === SAMPLING ===\n",
    "single_vector = mv_dist.sample()                    # Shape: [2]\n",
    "batch_vectors = mv_dist.sample(100)                 # Shape: [100, 2]\n",
    "seeded_sample = mv_dist.sample(100, seed=42)        # Reproducible\n",
    "\n",
    "# === PROBABILITY EVALUATION ===\n",
    "joint_prob = mv_dist.prob([0.5, 1.5])             # Joint PDF value\n",
    "joint_log_prob = mv_dist.log_prob([0.5, 1.5])     # Joint log PDF (preferred)\n",
    "batch_log_prob = mv_dist.log_prob([[0., 1.], [1., 0.]])  # Batch evaluation\n",
    "\n",
    "# === STATISTICS ===\n",
    "mean_vector = mv_dist.mean()                        # E[X] - vector\n",
    "cov_matrix = mv_dist.covariance()                  # Cov(X) - matrix\n",
    "var_vector = mv_dist.variance()                    # Var(X) - diagonal of covariance\n",
    "std_vector = mv_dist.stddev()                      # œÉ(X) - element-wise std dev\n",
    "\n",
    "# === SPECIAL OPERATIONS ===\n",
    "marginal_dist = mv_dist.marginal([0])              # Marginal distribution of X‚ÇÅ\n",
    "entropy_val = mv_dist.entropy()                    # Differential entropy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20e526c",
   "metadata": {},
   "source": [
    "## **Final Notes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c578102",
   "metadata": {},
   "source": [
    "- **The Multivariate Mindset**: While univariate distributions model individual uncertainties, multivariate distributions model **joint uncertainties and relationships**‚Äîcapturing how variables covary and influence each other.\n",
    "\n",
    "- **Start with Diagonal**: Begin with `MultivariateNormalDiag`. It's simpler and often sufficient. Move to full covariance only when you need to model correlations.\n",
    "\n",
    "- **Shape is Everything**: Master the `(sample_shape, batch_shape, event_shape)` hierarchy. This understanding transfers to all advanced TFP concepts.\n",
    "\n",
    "- **Correlation vs Independence**: The key power of multivariate distributions is modeling dependence. Use them when variables are naturally related.\n",
    "\n",
    "- **Numerical Stability**: Always use triangular parameterization (`MultivariateNormalTriL`) for learnable full covariance matrices."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Probabilistic-Deep-Learning-with-TensorFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
