{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae8af82",
   "metadata": {},
   "source": [
    "# **Sampling and Log Probabilities**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f077cde",
   "metadata": {},
   "source": [
    "## ðŸ“‘ Table of Contents\n",
    "\n",
    "- **1. [Foundation - What Are Sampling and Log Probabilities?](#1-foundation---what-are-sampling-and-log-probabilities)**\n",
    "    - 1.1 [The Big Picture](#11-the-big-picture)\n",
    "\n",
    "- **2. [Setup & Basic Concepts](#2-setup--basic-concepts)**\n",
    "    - 2.1 [Essential Imports & Setup](#21-essential-imports--setup)  \n",
    "    - 2.2 [Your First Sampling & Log Prob Operations](#22-your-first-sampling--log-prob-operations)\n",
    "\n",
    "- **3. [Basic Sampling Operations](#3-basic-sampling-operations)**\n",
    "    - 3.1 [Sampling from Batched Distributions](#31-sampling-from-batched-distributions)  \n",
    "    - 3.2 [Independent Wrapper for Joint Sampling](#32-independent-wrapper-for-joint-sampling)\n",
    "\n",
    "- **4. [Complex Multi-Dimensional Sampling](#4-complex-multi-dimensional-sampling)**\n",
    "    - 4.1 [Advanced Batch Structures](#41-advanced-batch-structures)  \n",
    "    - 4.2 [Multi-Dimensional Sampling](#42-multi-dimensional-sampling)\n",
    "\n",
    "- **5. [Log Probability Computations](#5-log-probability-computations)**\n",
    "    - 5.1 [Basic Log Probability Evaluation](#51-basic-log-probability-evaluation)  \n",
    "    - 5.2 [Vector Input Log Probability](#52-vector-input-log-probability)\n",
    "\n",
    "- **6. [Advanced Broadcasting & Shape Mechanics](#6-advanced-broadcasting--shape-mechanics)**\n",
    "    - 6.1 [Complex Broadcasting Patterns](#61-complex-broadcasting-patterns)  \n",
    "    - 6.2 [Multivariate Distribution with Independent](#62-multivariate-distribution-with-independent)\n",
    "\n",
    "- **7. [Professional Patterns & Best Practices](#7-professional-patterns--best-practices)**\n",
    "    - 7.1 [Efficient Sampling Strategies](#71-efficient-sampling-strategies)  \n",
    "    - 7.2 [Broadcasting Validation Utilities](#72-broadcasting-validation-utilities)  \n",
    "    - 7.3 [Probabilistic Training Loss Patterns](#73-probabilistic-training-loss-patterns)\n",
    "\n",
    "- **8. [Expert Applications](#8-expert-applications)**\n",
    "    - 8.1 [Monte Carlo Variational Inference](#81-monte-carlo-variational-inference)  \n",
    "    - 8.2 [Advanced Sampling Techniques](#82-advanced-sampling-techniques)\n",
    "\n",
    "- **9. [Complete Reference Guide](#9-complete-reference-guide)**\n",
    "    - 9.1 [Sampling Operations Reference](#91-sampling-operations-reference)  \n",
    "    - 9.2 [Log Probability Operations Reference](#92-log-probability-operations-reference)  \n",
    "    - 9.3 [Shape Rules for Sampling and Log Prob](#93-shape-rules-for-sampling-and-log-prob)\n",
    "\n",
    "- **[Learning Path](#learning-path)**\n",
    "\n",
    "- **[Final Notes](#final-notes)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106b9469",
   "metadata": {},
   "source": [
    "## 1. **Foundation - What Are Sampling and Log Probabilities?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e8f319",
   "metadata": {},
   "source": [
    "### 1.1 **The Big Picture**\n",
    "Sampling and log probability computations are the **core computational operations** in TensorFlow Probability. Every probabilistic machine learning algorithm relies on these two fundamental operations: **drawing samples** from distributions and **evaluating probabilities** of observed data.\n",
    "\n",
    "**Key Insight**: While `sample()` generates random data for Monte Carlo estimation and training, `log_prob()` evaluates how likely observed data is under your probabilistic modelâ€”the foundation of maximum likelihood estimation and Bayesian inference.[1]\n",
    "\n",
    "**Mathematical Foundation**:\n",
    "- **Sampling**: Generate `x ~ p(x)` for Monte Carlo approximation\n",
    "- **Log Probability**: Compute `log p(x)` for stable numerical likelihood evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dda5b75",
   "metadata": {},
   "source": [
    "## 2. **Setup & Basic Concepts**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cbd84d",
   "metadata": {},
   "source": [
    "### 2.1 **Essential Imports & Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b73974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing TensorFlow Probability library\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "\n",
    "# Standard alias for distributions\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21592a6b",
   "metadata": {},
   "source": [
    "### 2.2 **Your First Sampling & Log Prob Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e14ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Exponential(\"Exponential\", batch_shape=[2, 3], event_shape=[], dtype=float32)\n",
      "Batch shape: (2, 3)\n",
      "Event shape: ()\n"
     ]
    }
   ],
   "source": [
    "# Create a batched exponential distribution\n",
    "exp = tfd.Exponential(rate=[[1., 1.5, 0.8], [0.3, 0.4, 1.8]])\n",
    "print(exp)\n",
    "# Output: <tfp.distributions.Exponential 'Exponential' batch_shape=[2, 3] event_shape=[] dtype=float32>\n",
    "\n",
    "print(\"Batch shape:\", exp.batch_shape)  \n",
    "print(\"Event shape:\", exp.event_shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f5d850",
   "metadata": {},
   "source": [
    "**Key Properties**:\n",
    "- **`batch_shape=[2, 3]`**: 2Ã—3 = 6 independent exponential distributions\n",
    "- **`event_shape=[]`**: Each distribution produces scalar values\n",
    "- **`rate` parameter**: Different rates for each distribution in the batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9870771",
   "metadata": {},
   "source": [
    "## 3. **Basic Sampling Operations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ef566b",
   "metadata": {},
   "source": [
    "### 3.1 **Sampling from Batched Distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f29e989c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single sample shape: (2, 3)\n",
      "Single sample:\n",
      " tf.Tensor(\n",
      "[[4.390422   2.7434108  0.16488166]\n",
      " [0.350755   2.5880651  0.47506964]], shape=(2, 3), dtype=float32)\n",
      "Multiple samples shape: (4, 2, 3)\n",
      "Multiple samples:\n",
      " tf.Tensor(\n",
      "[[[2.1462562  0.86743593 0.0618375 ]\n",
      "  [2.3312993  2.7058575  0.34583405]]\n",
      "\n",
      " [[0.7877366  0.6282713  0.04425894]\n",
      "  [0.20140766 4.1841908  0.49354032]]\n",
      "\n",
      " [[0.07714589 0.8290665  0.32057405]\n",
      "  [3.3196666  0.78857696 0.37590277]]\n",
      "\n",
      " [[0.05160386 0.35619614 0.31295168]\n",
      "  [0.9867175  0.29580456 0.33078858]]], shape=(4, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Create batched exponential distribution\n",
    "exp = tfd.Exponential(rate=[[1., 1.5, 0.8], [0.3, 0.4, 1.8]])\n",
    "\n",
    "# Single sample from each distribution\n",
    "single_sample = exp.sample()\n",
    "print(\"Single sample shape:\", single_sample.shape)  # (2, 3)\n",
    "print(\"Single sample:\\n\", single_sample)\n",
    "\n",
    "# Multiple samples\n",
    "multiple_samples = exp.sample(4)  \n",
    "print(\"Multiple samples shape:\", multiple_samples.shape)  # (4, 2, 3)\n",
    "print(\"Multiple samples:\\n\", multiple_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f979deb",
   "metadata": {},
   "source": [
    "**Shape Analysis**:\n",
    "- **Single sample**: `shape = batch_shape + event_shape = (2, 3) + () = (2, 3)`\n",
    "- **Multiple samples**: `shape = sample_shape + batch_shape + event_shape = (4,) + (2, 3) + () = (4, 2, 3)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ca11e",
   "metadata": {},
   "source": [
    "### 3.1 **Independent Wrapper for Joint Sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8cbcb6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Independent(\"IndependentExponential\", batch_shape=[2], event_shape=[3], dtype=float32)\n",
      "Joint samples shape: (4, 2, 3)\n",
      "Joint samples:\n",
      " tf.Tensor(\n",
      "[[[2.6272154  2.051555   3.347836  ]\n",
      "  [1.6800407  0.51907015 0.9736745 ]]\n",
      "\n",
      " [[1.0240827  0.8342139  2.1261241 ]\n",
      "  [0.98191    1.8131511  0.6493894 ]]\n",
      "\n",
      " [[0.26463446 0.08187366 5.945581  ]\n",
      "  [5.35103    5.085251   0.5521324 ]]\n",
      "\n",
      " [[0.81465316 0.52829653 0.18442416]\n",
      "  [2.2659454  1.7780305  0.37588385]]], shape=(4, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Convert batched to multivariate using Independent\n",
    "exp = tfd.Exponential(rate=[[1., 1.5, 0.8], [0.3, 0.4, 1.8]])\n",
    "ind_exp = tfd.Independent(exp)  # Default reinterpreted_batch_ndims=1\n",
    "print(ind_exp)\n",
    "# Output: <tfp.distributions.Independent 'IndependentExponential' batch_shape=[2] event_shape=[2] dtype=float32>\n",
    "\n",
    "# Sample from Independent distribution\n",
    "joint_samples = ind_exp.sample(4)\n",
    "print(\"Joint samples shape:\", joint_samples.shape)  # (4, 2, 3)\n",
    "print(\"Joint samples:\\n\", joint_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f998e5c5",
   "metadata": {},
   "source": [
    "**Shape Transformation**:\n",
    "- **Original**: `batch_shape=[2, 3], event_shape=[]` â†’ 6 independent scalars\n",
    "- **After Independent**: `batch_shape=, event_shape=` â†’ 2 joint 3D vectors[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d13e34",
   "metadata": {},
   "source": [
    "## 4. **Complex Multi-Dimensional Sampling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba0b12a",
   "metadata": {},
   "source": [
    "### 4.1 **Advanced Batch Structures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b1049055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Exponential(\"Exponential\", batch_shape=[2, 1, 2, 3], event_shape=[], dtype=float32)\n",
      "tfp.distributions.Independent(\"IndependentExponential\", batch_shape=[2, 1], event_shape=[2, 3], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Create complex multi-dimensional batch structure\n",
    "rates = [\n",
    "    [[[1., 1.5, 0.8], [0.3, 0.4, 1.8]]],\n",
    "    [[[0.2, 0.4, 1.4], [0.4, 1.1, 0.9]]]\n",
    "]\n",
    "\n",
    "exp = tfd.Exponential(rate=rates)\n",
    "print(exp)\n",
    "# Output: batch_shape=[2, 1, 2, 3], event_shape=[]\n",
    "\n",
    "# Apply Independent with reinterpreted_batch_ndims=2\n",
    "ind_exp = tfd.Independent(exp, reinterpreted_batch_ndims=2)\n",
    "print(ind_exp)\n",
    "# Output: batch_shape=[2, 1], event_shape=[2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb71fe",
   "metadata": {},
   "source": [
    "**Complex Shape Analysis**:\n",
    "- **Original**: `batch_shape=[2, 1, 2, 3], event_shape=[]` â†’ 12 independent scalars\n",
    "- **After Independent**: `batch_shape=[2, 1], event_shape=[2, 3]` â†’ 2Ã—1 = 2 joint distributions over 2Ã—3 matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3ef0e",
   "metadata": {},
   "source": [
    "### 4.2 **Multi-Dimensional Sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e15fdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex samples shape: (4, 2, 2, 1, 2, 3)\n",
      "Complex samples structure:\n",
      "  Sample shape: [4, 2]\n",
      "  Batch shape: [2, 1]\n",
      "  Event shape: [2, 3]\n",
      "  Final shape: (4, 2, 2, 1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# Sample with specific sample shape\n",
    "rates = [\n",
    "    [[[1., 1.5, 0.8], [0.3, 0.4, 1.8]]],\n",
    "    [[[0.2, 0.4, 1.4], [0.4, 1.1, 0.9]]]\n",
    "]\n",
    "\n",
    "exp = tfd.Exponential(rate=rates)\n",
    "ind_exp = tfd.Independent(exp, reinterpreted_batch_ndims=2)\n",
    "\n",
    "# Sample with shape [4, 2]\n",
    "complex_samples = ind_exp.sample([4, 2])\n",
    "print(\"Complex samples shape:\", complex_samples.shape)  \n",
    "print(\"Complex samples structure:\")\n",
    "print(\"  Sample shape: [4, 2]\")\n",
    "print(\"  Batch shape: [2, 1]\") \n",
    "print(\"  Event shape: [2, 3]\")\n",
    "print(\"  Final shape: (4, 2, 2, 1, 2, 3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f2fd8",
   "metadata": {},
   "source": [
    "## 5. **Log Probability Computations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9588a897",
   "metadata": {},
   "source": [
    "### 5.1 **Basic Log Probability Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5243a4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar log prob shape: (2, 1)\n",
      "Scalar log prob values: tf.Tensor(\n",
      "[[-4.2501554]\n",
      " [-5.3155975]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Create the same distribution structure\n",
    "rates = [\n",
    "    [[[1., 1.5, 0.8], [0.3, 0.4, 1.8]]],\n",
    "    [[[0.2, 0.4, 1.4], [0.4, 1.1, 0.9]]]\n",
    "]\n",
    "\n",
    "exp = tfd.Exponential(rate=rates)\n",
    "ind_exp = tfd.Independent(exp, reinterpreted_batch_ndims=2)\n",
    "\n",
    "# Single scalar input (broadcasts across all distributions)\n",
    "scalar_log_prob = ind_exp.log_prob(0.5)\n",
    "print(\"Scalar log prob shape:\", scalar_log_prob.shape)  \n",
    "print(\"Scalar log prob values:\", scalar_log_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6851c326",
   "metadata": {},
   "source": [
    "**Broadcasting Behavior**:\n",
    "- **Input**: `0.5` (scalar)\n",
    "- **Distribution event_shape**: `[2, 3]` \n",
    "- **Broadcasting**: Scalar expands to `[2, 3]` filled with `0.5`\n",
    "- **Output**: `(2, 1)` - one log probability per batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c2548",
   "metadata": {},
   "source": [
    "### 5.2 **Vector Input Log Probability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6596133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector log prob shape: (2, 1)\n",
      "Vector log prob values: tf.Tensor(\n",
      "[[-4.7701554]\n",
      " [-5.8855977]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Vector input matching event shape\n",
    "rates = [\n",
    "    [[[1., 1.5, 0.8], [0.3, 0.4, 1.8]]],\n",
    "    [[[0.2, 0.4, 1.4], [0.4, 1.1, 0.9]]]\n",
    "]\n",
    "\n",
    "exp = tfd.Exponential(rate=rates)\n",
    "ind_exp = tfd.Independent(exp, reinterpreted_batch_ndims=2)\n",
    "\n",
    "# Input shape (1, 3) - partially matches event_shape \n",
    "vector_input = [[0.3, 0.5, 0.8]]  # Shape: (1, 3)\n",
    "vector_log_prob = ind_exp.log_prob(vector_input)\n",
    "print(\"Vector log prob shape:\", vector_log_prob.shape)  \n",
    "print(\"Vector log prob values:\", vector_log_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66f8b6a",
   "metadata": {},
   "source": [
    "## 6. **Advanced Broadcasting & Shape Mechanics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eaf4b5",
   "metadata": {},
   "source": [
    "### 6.1 **Complex Broadcasting Patterns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "99b4d621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex input shape: (5, 1, 1, 2, 1)\n",
      "Complex log prob shape: (5, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "tfd = tfp.distributions\n",
    "\n",
    "# Create complex distribution structure\n",
    "rates = [\n",
    "    [[[1., 1.5, 0.8], [0.3, 0.4, 1.8]]],\n",
    "    [[[0.2, 0.4, 1.4], [0.4, 1.1, 0.9]]]\n",
    "]\n",
    "\n",
    "exp = tfd.Exponential(rate=rates)\n",
    "ind_exp = tfd.Independent(exp, reinterpreted_batch_ndims=2)\n",
    "\n",
    "# Complex input with shape\n",
    "complex_input = tf.random.uniform((5, 1, 1, 2, 1))\n",
    "print(\"Complex input shape:\", complex_input.shape)  \n",
    "\n",
    "complex_log_prob = ind_exp.log_prob(complex_input)\n",
    "print(\"Complex log prob shape:\", complex_log_prob.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5efdc2",
   "metadata": {},
   "source": [
    "**Advanced Broadcasting Rules**:\n",
    "- **Distribution**: `batch_shape=[2, 1], event_shape=[2, 3]`\n",
    "- **Input**: `(5, 1, 1, 2, 1)`\n",
    "- **Broadcasting**: Input shape aligns with batch + event dimensions\n",
    "- **Output**: Broadcasted result based on TensorFlow broadcasting rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74af0960",
   "metadata": {},
   "source": [
    "### 6.2 **Multivariate Distribution with Independent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c548840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base distribution:\n",
      "  batch_shape: (2, 3)\n",
      "  event_shape: (4,)\n",
      "After Independent:\n",
      "  batch_shape: (2,)\n",
      "  event_shape: (3, 4)\n",
      "Result shape: (2, 2)\n"
     ]
    }
   ],
   "source": [
    "tfd = tfp.distributions\n",
    "\n",
    "# Create multivariate distribution with Independent wrapper\n",
    "loc = tf.zeros((2, 3, 1))          # Shape: (2, 3, 1)\n",
    "scale_diag = tf.ones(4)            # Shape: (4,)\n",
    "\n",
    "# Create base multivariate normal\n",
    "base_mv_normal = tfd.MultivariateNormalDiag(loc=loc, scale_diag=scale_diag)\n",
    "print(\"Base distribution:\")\n",
    "print(f\"  batch_shape: {base_mv_normal.batch_shape}\")  \n",
    "print(f\"  event_shape: {base_mv_normal.event_shape}\") \n",
    "\n",
    "# Wrap with Independent\n",
    "dist = tfd.Independent(base_mv_normal)  # Default reinterpreted_batch_ndims=1\n",
    "print(\"After Independent:\")\n",
    "print(f\"  batch_shape: {dist.batch_shape}\")  \n",
    "print(f\"  event_shape: {dist.event_shape}\")  \n",
    "\n",
    "# Log probability evaluation\n",
    "test_input = tf.random.uniform((2, 1, 1, 4))\n",
    "result_log_prob = dist.log_prob(test_input)\n",
    "print(\"Result shape:\", result_log_prob.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a069fd",
   "metadata": {},
   "source": [
    "**Multivariate + Independent Analysis**:\n",
    "- **Base**: MultivariateNormal with `batch_shape=[2, 3, 1], event_shape=`[5]\n",
    "- **Independent**: Moves last batch dimension to event: `batch_shape=[2, 3], event_shape=[1, 4]`\n",
    "- **Result**: Joint log probability over `[1, 4]` dimensional events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c53769d",
   "metadata": {},
   "source": [
    "## 7. **Professional Patterns & Best Practices**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb01912",
   "metadata": {},
   "source": [
    "### 7.1 **Efficient Sampling Strategies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e9d60eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples shape: (5000, 10)\n",
      "Log probs shape: (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "def efficient_monte_carlo_estimation(distribution, n_samples=1000, chunk_size=100):\n",
    "    \"\"\"\n",
    "    Memory-efficient Monte Carlo sampling for large n_samples\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    log_probs = []\n",
    "    \n",
    "    for i in range(0, n_samples, chunk_size):\n",
    "        current_chunk = min(chunk_size, n_samples - i)\n",
    "        \n",
    "        # Sample and evaluate in chunks to manage memory\n",
    "        chunk_samples = distribution.sample(current_chunk)\n",
    "        chunk_log_probs = distribution.log_prob(chunk_samples)\n",
    "        \n",
    "        samples.append(chunk_samples)\n",
    "        log_probs.append(chunk_log_probs)\n",
    "    \n",
    "    return tf.concat(samples, axis=0), tf.concat(log_probs, axis=0)\n",
    "\n",
    "# Example usage\n",
    "dist = tfd.Independent(tfd.Normal(loc=tf.zeros(10), scale=tf.ones(10)))\n",
    "samples, log_probs = efficient_monte_carlo_estimation(dist, n_samples=5000)\n",
    "print(f\"Samples shape: {samples.shape}\")    \n",
    "print(f\"Log probs shape: {log_probs.shape}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e0caea",
   "metadata": {},
   "source": [
    "### 7.2 **Broadcasting Validation Utilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4e2a1704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOG PROB INPUT VALIDATION ===\n",
      "Distribution batch_shape: (3,)\n",
      "Distribution event_shape: (4,)\n",
      "Input tensor shape: (2, 1, 4)\n",
      "âœ… Event shape compatible\n",
      "âœ… Expected output shape: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "def validate_log_prob_input_shape(distribution, input_tensor):\n",
    "    \"\"\"\n",
    "    Validate that input tensor can be evaluated by distribution.log_prob()\n",
    "    \"\"\"\n",
    "    batch_shape = distribution.batch_shape\n",
    "    event_shape = distribution.event_shape\n",
    "    input_shape = input_tensor.shape\n",
    "    \n",
    "    print(\"=== LOG PROB INPUT VALIDATION ===\")\n",
    "    print(f\"Distribution batch_shape: {batch_shape}\")\n",
    "    print(f\"Distribution event_shape: {event_shape}\")\n",
    "    print(f\"Input tensor shape: {input_shape}\")\n",
    "    \n",
    "    # Check if input is compatible with event shape\n",
    "    event_ndims = len(event_shape)\n",
    "    if len(input_shape) < event_ndims:\n",
    "        print(\"âŒ ERROR: Input rank too small for event shape\")\n",
    "        return False\n",
    "    \n",
    "    input_event_shape = input_shape[-event_ndims:] if event_ndims > 0 else []\n",
    "    \n",
    "    # Check event shape compatibility\n",
    "    try:\n",
    "        tf.broadcast_static_shape(input_event_shape, event_shape)\n",
    "        print(\"âœ… Event shape compatible\")\n",
    "    except tf.errors.InvalidArgumentError:\n",
    "        print(\"âŒ ERROR: Input event shape incompatible\")\n",
    "        return False\n",
    "    \n",
    "    # Predict output shape\n",
    "    try:\n",
    "        sample_and_batch_shape = input_shape[:-event_ndims] if event_ndims > 0 else input_shape\n",
    "        output_shape = tf.broadcast_static_shape(sample_and_batch_shape, batch_shape)\n",
    "        print(f\"âœ… Expected output shape: {output_shape}\")\n",
    "        return True\n",
    "    except tf.errors.InvalidArgumentError:\n",
    "        print(\"âŒ ERROR: Batch broadcasting will fail\")\n",
    "        return False\n",
    "\n",
    "# Example validation\n",
    "dist = tfd.Independent(tfd.Normal(loc=tf.zeros((3, 4)), scale=tf.ones((3, 4))))\n",
    "input_tensor = tf.random.normal((2, 1, 4))\n",
    "is_valid = validate_log_prob_input_shape(dist, input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdebb1b5",
   "metadata": {},
   "source": [
    "### 7.3 **Probabilistic Training Loss Patterns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ebb474b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbabilisticLoss(tf.keras.losses.Loss):\n",
    "    \"\"\"\n",
    "    Custom loss for probabilistic outputs using log_prob\n",
    "    \"\"\"\n",
    "    def __init__(self, reduction=tf.keras.losses.Reduction.AUTO, name='probabilistic_loss'):\n",
    "        super().__init__(reduction=reduction, name=name)\n",
    "    \n",
    "    def call(self, y_true, y_pred_distribution):\n",
    "        \"\"\"\n",
    "        y_true: Ground truth values\n",
    "        y_pred_distribution: TFP Distribution object\n",
    "        \"\"\"\n",
    "        # Negative log likelihood\n",
    "        nll = -y_pred_distribution.log_prob(y_true)\n",
    "        return nll\n",
    "\n",
    "# Example usage in training\n",
    "@tf.function\n",
    "def train_step_with_sampling(features, targets, model, optimizer):\n",
    "    \"\"\"\n",
    "    Training step that uses both sampling and log_prob\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Model outputs distribution\n",
    "        pred_distribution = model(features, training=True)\n",
    "        \n",
    "        # Main loss: negative log likelihood\n",
    "        nll_loss = -tf.reduce_mean(pred_distribution.log_prob(targets))\n",
    "        \n",
    "        # Regularization using samples\n",
    "        samples = pred_distribution.sample(5)\n",
    "        sample_std = tf.math.reduce_std(samples, axis=0)\n",
    "        regularization = 0.01 * tf.reduce_mean(sample_std)  # Encourage diversity\n",
    "        \n",
    "        total_loss = nll_loss + regularization\n",
    "    \n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return {\n",
    "        'total_loss': total_loss,\n",
    "        'nll_loss': nll_loss,\n",
    "        'regularization': regularization\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36499fc",
   "metadata": {},
   "source": [
    "## 8. **Expert Applications**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0bbde3",
   "metadata": {},
   "source": [
    "### 8.1 **Monte Carlo Variational Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d2510d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_elbo(encoder, decoder, data, n_samples=10):\n",
    "    \"\"\"\n",
    "    Compute ELBO using Monte Carlo estimation with sampling and log_prob\n",
    "    \"\"\"\n",
    "    # Encode to get posterior distribution\n",
    "    posterior = encoder(data)\n",
    "    \n",
    "    # Sample from posterior\n",
    "    z_samples = posterior.sample(n_samples)  # Shape: (n_samples, batch_size, latent_dim)\n",
    "    \n",
    "    # Decode samples\n",
    "    reconstruction_logits = decoder(z_samples)\n",
    "    \n",
    "    # Prior distribution\n",
    "    prior = tfd.Independent(tfd.Normal(loc=0., scale=1.), reinterpreted_batch_ndims=1)\n",
    "    \n",
    "    # Compute ELBO components\n",
    "    # 1. Reconstruction term: E_q[log p(x|z)]\n",
    "    reconstruction_dist = tfd.Independent(\n",
    "        tfd.Bernoulli(logits=reconstruction_logits), \n",
    "        reinterpreted_batch_ndims=1\n",
    "    )\n",
    "    reconstruction_term = tf.reduce_mean(reconstruction_dist.log_prob(data))\n",
    "    \n",
    "    # 2. KL divergence: E_q[log q(z|x) - log p(z)]\n",
    "    posterior_log_prob = tf.reduce_mean(posterior.log_prob(z_samples))\n",
    "    prior_log_prob = tf.reduce_mean(prior.log_prob(z_samples))\n",
    "    kl_divergence = posterior_log_prob - prior_log_prob\n",
    "    \n",
    "    # ELBO = Reconstruction - KL\n",
    "    elbo = reconstruction_term - kl_divergence\n",
    "    \n",
    "    return {\n",
    "        'elbo': elbo,\n",
    "        'reconstruction': reconstruction_term,\n",
    "        'kl_divergence': kl_divergence\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608e77c1",
   "metadata": {},
   "source": [
    "### 8.2 **Advanced Sampling Techniques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39a86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated E[X^2]: 26.391807556152344\n",
      "Effective sample size: 568.8297119140625\n"
     ]
    }
   ],
   "source": [
    "class ImportanceSampler:\n",
    "    \"\"\"\n",
    "    Importance sampling using proposal distribution\n",
    "    \"\"\"\n",
    "    def __init__(self, target_distribution, proposal_distribution):\n",
    "        self.target = target_distribution\n",
    "        self.proposal = proposal_distribution\n",
    "    \n",
    "    def sample(self, n_samples):\n",
    "        \"\"\"\n",
    "        Generate importance-weighted samples\n",
    "        \"\"\"\n",
    "        # Sample from proposal\n",
    "        samples = self.proposal.sample(n_samples)\n",
    "        \n",
    "        # Compute importance weights\n",
    "        target_log_prob = self.target.log_prob(samples)\n",
    "        proposal_log_prob = self.proposal.log_prob(samples)\n",
    "        log_weights = target_log_prob - proposal_log_prob\n",
    "        \n",
    "        # Normalize weights\n",
    "        weights = tf.nn.softmax(log_weights)\n",
    "        \n",
    "        return {\n",
    "            'samples': samples,\n",
    "            'weights': weights,\n",
    "            'log_weights': log_weights,\n",
    "            'effective_sample_size': 1.0 / tf.reduce_sum(weights**2)\n",
    "        }\n",
    "    \n",
    "    def estimate_expectation(self, function, n_samples):\n",
    "        \"\"\"\n",
    "        Estimate E_target[function(X)] using importance sampling\n",
    "        \"\"\"\n",
    "        result = self.sample(n_samples)\n",
    "        function_values = function(result['samples'])\n",
    "        \n",
    "        # Weighted average\n",
    "        expectation = tf.reduce_sum(result['weights'] * function_values)\n",
    "        \n",
    "        return expectation, result['effective_sample_size']\n",
    "\n",
    "# Example usage\n",
    "target = tfd.Normal(loc=5., scale=1.)\n",
    "proposal = tfd.Normal(loc=4., scale=2.)\n",
    "sampler = ImportanceSampler(target, proposal)\n",
    "\n",
    "# Estimate E[X^2] under target distribution\n",
    "def square_function(x):\n",
    "    return x**2\n",
    "\n",
    "expectation, ess = sampler.estimate_expectation(square_function, n_samples=1000)\n",
    "print(f\"Estimated E[X^2]: {expectation}\")\n",
    "print(f\"Effective sample size: {ess}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4ab65c",
   "metadata": {},
   "source": [
    "## 9. **Complete Reference Guide**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ef38a0",
   "metadata": {},
   "source": [
    "### 9.1 **Sampling Operations Reference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "44470178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single sample: -0.5220753\n",
      "Batch samples: [-0.1365969  -1.218801   -0.9215488   2.7218962   1.5125786   1.4108888\n",
      "  1.6950028   1.4028981   0.7990797  -0.65465575  1.0263169   0.8830985\n",
      "  0.04019995 -1.0114911   0.25672132 -0.0426529   0.17955922 -0.99527174\n",
      " -0.601428    1.4637355   1.6804155  -0.70276546 -0.9713734  -1.0440786\n",
      " -0.86533374  0.02161358  0.7340682   2.1229079   0.7858814  -0.5298925\n",
      " -1.0749215   1.1408054   0.3555776  -0.08745395  0.00865405 -1.32541\n",
      "  0.39447325  0.56572866  0.25718474  0.77076024  0.8543685  -1.1066352\n",
      " -0.62045103  0.98014045 -0.30651346  1.415835   -1.933607    0.85357845\n",
      "  1.3835907   0.25166965 -1.2337768   1.040264   -2.7738826  -0.6555695\n",
      "  2.380446   -1.4398961  -0.21188603 -0.09578023  0.5760158   0.41028446\n",
      " -0.93355393  1.5430417  -2.0077636   0.45634276 -1.5455538  -0.21137801\n",
      "  0.60432875  1.9447913  -1.3108555  -1.3553311  -1.6904684   0.6628786\n",
      "  0.64199805  0.30658808  2.322921   -1.2522532   0.9507786   1.1831026\n",
      "  1.0265836  -0.67858493 -1.2120677  -0.6385424  -0.93031543  1.1304743\n",
      "  0.5717989  -0.31339905 -0.992359   -0.66067636  0.05468331 -0.02239556\n",
      " -0.13421923  0.08097219 -0.8455511   1.2402557  -1.0119678  -0.08862612\n",
      "  0.41137403 -0.29498816  0.03510866  0.6051137 ]\n",
      "Seeded samples: [ 1.3148774  -0.15421568  0.9113878  -0.7991441  -0.10875293  0.28436786\n",
      "  0.7661625  -0.6211289   0.9974318   0.21959257 -1.0798668  -1.9874831\n",
      "  1.5603696  -0.16909476 -1.3780487  -0.29801553  0.8410001   0.9225498\n",
      " -0.48379228 -1.6971248   0.09536484 -0.10675382 -1.7839274   1.7145915\n",
      " -1.1761415   1.1488945   0.4505377  -0.81724054  0.95193976  1.3913034\n",
      "  0.15862282  0.10488074  1.1451166  -1.0479503   0.21458012  0.25750676\n",
      " -0.99603957  0.55202    -0.8870138   3.4017045   0.34291962 -0.4389471\n",
      " -1.5277438  -0.8316435   0.3434062  -2.7989998  -0.9340011  -0.40604064\n",
      "  1.2880986   1.2897398  -0.3741515  -1.4218495  -0.13424467  1.0253482\n",
      " -3.2489176   1.8755275   0.8539876   0.6199211  -0.21415219  2.0731623\n",
      "  0.19485866 -0.36870828  0.32352057  1.7784952   0.67288345  1.192604\n",
      "  0.02937807  1.3695234  -0.84422374  0.14643075 -2.167099   -0.54043925\n",
      " -1.3511175  -1.1596807  -0.27452996 -0.7361402   0.38832134 -0.24853493\n",
      " -0.79855597 -0.46657825  1.1286335  -1.1491549   0.2331937  -0.75925595\n",
      "  0.38633636 -1.4149377  -1.7656256  -0.665978   -0.5536773  -1.4172283\n",
      "  1.1051842   1.2187223  -0.6621953   0.7448888  -1.1173725   0.71882343\n",
      "  0.5128387  -0.7941299   1.241065   -0.8387284 ]\n"
     ]
    }
   ],
   "source": [
    "# === BASIC SAMPLING ===\n",
    "dist = tfd.Normal(loc=0., scale=1.)\n",
    "single = dist.sample()                          # Shape: ()\n",
    "batch = dist.sample(100)                        # Shape: (100,)\n",
    "seeded = dist.sample(100, seed=42)              # Reproducible\n",
    "\n",
    "print(\"Single sample:\", single.numpy())\n",
    "print(\"Batch samples:\", batch.numpy())\n",
    "print(\"Seeded samples:\", seeded.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "104f2bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch samples shape: (50, 2)\n"
     ]
    }
   ],
   "source": [
    "# === BATCH SAMPLING ===\n",
    "batch_dist = tfd.Normal(loc=[0., 1.], scale=[1., 2.])\n",
    "batch_samples = batch_dist.sample(50)           # Shape: (50, 2)\n",
    "\n",
    "print(\"Batch samples shape:\", batch_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2add0849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate samples shape: (30, 2)\n"
     ]
    }
   ],
   "source": [
    "# === MULTIVARIATE SAMPLING ===\n",
    "mv_dist = tfd.MultivariateNormalDiag(loc=[0., 1.], scale_diag=[1., 2.])\n",
    "mv_samples = mv_dist.sample(30)                 # Shape: (30, 2)\n",
    "print(\"Multivariate samples shape:\", mv_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "752aab70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate samples shape: (30, 2)\n"
     ]
    }
   ],
   "source": [
    "# === INDEPENDENT SAMPLING ===\n",
    "indep_dist = tfd.Independent(tfd.Normal(loc=tf.zeros(5), scale=tf.ones(5)))\n",
    "indep_samples = indep_dist.sample(20)           # Shape: (20, 5)\n",
    "print(\"Multivariate samples shape:\", mv_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "efa31f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex samples shape: (10, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "# === COMPLEX SAMPLING ===\n",
    "complex_samples = dist.sample([10, 3, 2])       # Shape: (10, 3, 2) + batch_shape + event_shape\n",
    "print(\"Complex samples shape:\", complex_samples.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df872d51",
   "metadata": {},
   "source": [
    "### 9.2 **Log Probability Operations Reference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5745086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-0.9189385, shape=(), dtype=float32)\n",
      "tf.Tensor([-0.9189385 -1.4189385 -2.9189386], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Creating distribution\n",
    "dist = tfd.Normal(loc=0., scale=1.)\n",
    "print(dist.log_prob(0.))                        # Scalar input\n",
    "print(dist.log_prob([0., 1., 2.]))              # Vector input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "06869936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar log prob: -1.0439385\n",
      "Vector log prob: [-0.9189385 -1.4189385 -2.9189386]\n"
     ]
    }
   ],
   "source": [
    "# === BASIC LOG PROB ===\n",
    "scalar_log_prob = dist.log_prob(0.5)            # Shape: ()\n",
    "vector_log_prob = dist.log_prob([0., 1., 2.])   # Shape: (3,)\n",
    "\n",
    "print(\"Scalar log prob:\", scalar_log_prob.numpy())\n",
    "print(\"Vector log prob:\", vector_log_prob.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f78aca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch log prob: [-1.0439385 -1.6433357]\n"
     ]
    }
   ],
   "source": [
    "# === BATCH LOG PROB ===\n",
    "batch_dist = tfd.Normal(loc=[0., 1.], scale=[1., 2.])\n",
    "batch_log_prob = batch_dist.log_prob([0.5, 1.5])  \n",
    "\n",
    "print(\"Batch log prob:\", batch_log_prob.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fbe518e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate log prob: -2.6872742\n"
     ]
    }
   ],
   "source": [
    "# === MULTIVARIATE LOG PROB ===\n",
    "mv_dist = tfd.MultivariateNormalDiag(loc=[0., 1.], scale_diag=[1., 2.])\n",
    "mv_log_prob = mv_dist.log_prob([0.5, 1.5])      # Shape: () - joint probability\n",
    "\n",
    "print(\"Multivariate log prob:\", mv_log_prob.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f7dd3ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Independent log prob: [-0.9189385 -1.4189385 -2.9189386]\n"
     ]
    }
   ],
   "source": [
    "# === INDEPENDENT LOG PROB ===\n",
    "indep_dist = tfd.Independent(tfd.Normal(loc=tf.zeros(3), scale=tf.ones(3)))\n",
    "indep_log_prob = indep_dist.log_prob([0., 1., 2.])  # Shape: () - sum of components\n",
    "print(\"Independent log prob:\", indep_log_prob.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7e9f13d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broadcast log prob shape: (5, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "# === BROADCASTING LOG PROB ===\n",
    "broadcast_log_prob = dist.log_prob(tf.ones((5, 3, 2)))  # Broadcasting rules apply\n",
    "print(\"Broadcast log prob shape:\", broadcast_log_prob.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d1017",
   "metadata": {},
   "source": [
    "### 9.3 **Shape Rules for Sampling and Log Prob**\n",
    "\n",
    "| **Operation** | **Distribution Shape** | **Input/Sample Shape** | **Output Shape** |\n",
    "|---------------|------------------------|------------------------|------------------|\n",
    "| **`sample()`** | `batch=[B], event=[E]` | `sample=[S]` | `[S] + [B] + [E]` |\n",
    "| **`sample(n)`** | `batch=[B], event=[E]` | `n` (scalar) | `[n] + [B] + [E]` |\n",
    "| **`log_prob(x)`** | `batch=[B], event=[E]` | `x.shape` | `broadcast([x.shape[:-len(E)]], [B])` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e8478d",
   "metadata": {},
   "source": [
    "## ðŸ’¡ **Final Notes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af227646",
   "metadata": {},
   "source": [
    "- **The Sampling-Inference Cycle**: Modern probabilistic ML alternates between **sampling** (generating data, exploring parameter space) and **log_prob evaluation** (measuring likelihood, computing gradients). Master both to unlock the full power of probabilistic modeling.\n",
    "\n",
    "- **Memory vs Accuracy Trade-off**: Large sample sizes give better Monte Carlo estimates but consume more memory. Use chunked sampling for large-scale problems.\n",
    "\n",
    "- **Log-Space Numerics**: Always use `log_prob()` instead of `prob()` for numerical stability. Probabilities can underflow, but log probabilities remain stable.\n",
    "\n",
    "- **Shape Debugging Strategy**: When shapes don't work, trace through: `sample_shape + batch_shape + event_shape` for sampling, and broadcasting rules for log_prob inputs.\n",
    "\n",
    "- **Broadcasting is Your Friend**: TFP's broadcasting enables vectorized operations across complex hierarchies. Learn it wellâ€”it's essential for efficient probabilistic computation.\n",
    "\n",
    "- **Gradient Flow**: `log_prob()` is differentiable through its inputs and distribution parameters. This enables gradient-based optimization of probabilistic modelsâ€”the foundation of modern deep learning.\n",
    "\n",
    "- Sampling and log probabilities are the **computational engines** of probabilistic machine learning. Every advanced techniqueâ€”from VAEs to Bayesian neural networks to MCMCâ€”builds on these fundamental operations. Master them, and you unlock the full potential of uncertainty quantification and probabilistic reasoning! ðŸš€\n",
    "\n",
    "\n",
    "> Once comfortable with sampling and log probabilities, explore bijectors for distribution transformations, custom training loops with `tf.GradientTape`, and advanced inference techniques like Hamiltonian Monte Carlo to build cutting-edge probabilistic systems.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Probabilistic-Deep-Learning-with-TensorFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
